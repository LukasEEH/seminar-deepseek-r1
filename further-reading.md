
## Further reading

#### General paper understanding:
* [Understanding the DeepSeek R1 Paper (huggingface.co)](https://huggingface.co/learn/llm-course/chapter12/3)



#### Reinforcement Learning and GRPO:
* [Introduction to Reinforcement Learning and its Role in LLMs (huggingface.co)](https://huggingface.co/learn/llm-course/chapter12/2)

* [GRPO Trainer with example (TRL library, huggingface.co)](https://huggingface.co/docs/trl/main/en/grpo_trainer)

* [What is GRPO? The RL algorithm used to train DeepSeek (medium.com)](https://medium.com/data-science-in-your-pocket/what-is-grpo-the-rl-algorithm-used-to-train-deepseek-12acc19798d3)

* [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models (Paper where GRPO was introduced, arxiv.org)](https://arxiv.org/abs/2402.03300)



#### Knowledge Distillation:

* [Shrinking the Giants: How knowledge distillation is Changing the Landscape of Deep Learning Models (medium.com)](https://medium.com/@zone24x7_inc/shrinking-the-giants-how-knowledge-distillation-is-changing-the-landscape-of-deep-learning-models-83dffde577ec)

* [How ChatGPT Cheaps Out Over Time (Video about distillation, youtube.com)](https://youtu.be/vyJy-0zBSQ0)